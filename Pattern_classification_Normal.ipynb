{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import AveragePooling2D,GlobalAveragePooling2D,Concatenate,Lambda\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MasterImage(object):\n",
    "\n",
    "    def __init__(self,PATH='', IMAGE_SIZE = 50):\n",
    "        self.PATH = PATH\n",
    "        self.IMAGE_SIZE = IMAGE_SIZE\n",
    "\n",
    "        self.image_data = []\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        self.CATEGORIES = []\n",
    "\n",
    "        # This will get List of categories\n",
    "        self.list_categories = []\n",
    "\n",
    "    def get_categories(self):\n",
    "        for path in os.listdir(self.PATH):\n",
    "            if '.DS_Store' in path:\n",
    "                pass\n",
    "            else:\n",
    "                self.list_categories.append(path)\n",
    "        print(\"Found Categories \",self.list_categories,'\\n')\n",
    "        return self.list_categories\n",
    "\n",
    "    def Process_Image(self):\n",
    "        try:\n",
    "            \"\"\"\n",
    "            Return Numpy array of image\n",
    "            :return: X_Data, Y_Data\n",
    "            \"\"\"\n",
    "            self.CATEGORIES = self.get_categories()\n",
    "            for categories in self.CATEGORIES:                                                  # Iterate over categories\n",
    "\n",
    "                train_folder_path = os.path.join(self.PATH, categories)                         # Folder Path\n",
    "                class_index = self.CATEGORIES.index(categories)                                 # this will get index for classification\n",
    "\n",
    "                for img in os.listdir(train_folder_path):                                       # This will iterate in the Folder\n",
    "                    new_path = os.path.join(train_folder_path, img)                             # image Path\n",
    "\n",
    "                    try:        # if any image is corrupted\n",
    "                        image_data_temp = cv2.imread(new_path,cv2.IMREAD_GRAYSCALE)                 # Read Image as numbers\n",
    "                        image_temp_resize = cv2.resize(image_data_temp,(self.IMAGE_SIZE,self.IMAGE_SIZE))\n",
    "                        self.image_data.append([image_temp_resize,class_index])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            data = np.asanyarray(self.image_data)\n",
    "\n",
    "            # Iterate over the Data\n",
    "            for x in data:\n",
    "                self.x_data.append(x[0])        # Get the X_Data\n",
    "                self.y_data.append(x[1])        # get the label\n",
    "\n",
    "            X_Data = np.asarray(self.x_data) / (255.0)      # Normalize Data\n",
    "            Y_Data = np.asarray(self.y_data)\n",
    "\n",
    "            # reshape x_Data\n",
    "\n",
    "            X_Data = X_Data.reshape(-1, self.IMAGE_SIZE, self.IMAGE_SIZE, 1)\n",
    "\n",
    "            return X_Data, Y_Data\n",
    "        except:\n",
    "            print(\"Failed to run Function Process Image \")\n",
    "\n",
    "    def pickle_image(self):\n",
    "\n",
    "        \"\"\"\n",
    "        :return: None Creates a Pickle Object of DataSet\n",
    "        \"\"\"\n",
    "        # Call the Function and Get the Data\n",
    "        X_Data,Y_Data = self.Process_Image()\n",
    "\n",
    "        # Write the Entire Data into a Pickle File\n",
    "        pickle_out = open('X_Data','wb')\n",
    "        pickle.dump(X_Data, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # Write the Y Label Data\n",
    "        pickle_out = open('Y_Data', 'wb')\n",
    "        pickle.dump(Y_Data, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        print(\"Pickled Image Successfully \")\n",
    "        return X_Data,Y_Data\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        try:\n",
    "            # Read the Data from Pickle Object\n",
    "            X_Temp = open('X_Data','rb')\n",
    "            X_Data = pickle.load(X_Temp)\n",
    "\n",
    "            Y_Temp = open('Y_Data','rb')\n",
    "            Y_Data = pickle.load(Y_Temp)\n",
    "\n",
    "            print('Reading Dataset from PIckle Object')\n",
    "\n",
    "            return X_Data,Y_Data\n",
    "\n",
    "        except:\n",
    "            print('Could not Found Pickle File ')\n",
    "            print('Loading File and Dataset  ..........')\n",
    "\n",
    "            X_Data,Y_Data = self.pickle_image()\n",
    "            return X_Data,Y_Data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
